{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb37d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import face_recognition_models\n",
    "import dlib\n",
    "import os\n",
    "from mediapipe.python.solutions.drawing_utils import _normalized_to_pixel_coordinates\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "import face_recognition\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a7d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognition_model = face_recognition_models.face_recognition_model_location()\n",
    "face_encoder = dlib.face_recognition_model_v1(face_recognition_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5795dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_points_68 = [162,234,93,58,172,136,149,148,152,377,378,365,397,288,323,454,389,71,63,105,66,107,336,\n",
    "                  296,334,293,301,168,197,5,4,75,97,2,326,305,33,160,158,133,153,144,362,385,387,263,373,\n",
    "                  380,61,39,37,0,267,269,291,405,314,17,84,181,78,82,13,312,308,317,14,87]\n",
    "    \n",
    "landmark_points_5_1 = [ 2, #bottom of nose tip\n",
    "                     362, #left eye towards centre\n",
    "                     263, #left eye away from centre\n",
    "                     33,  #right eye away from centre\n",
    "                     133 #right eye towards centre \n",
    "                    ]\n",
    "landmark_points_5_2 = [ 2, #bottom of nose tip\n",
    "                     263, #left eye away from centre\n",
    "                     362, #left eye towards centre\n",
    "                     133, #right eye towards centre \n",
    "                     33  #right eye away from centre\n",
    "                    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9f35cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.7)\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1,min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028bb5f",
   "metadata": {},
   "source": [
    "### MP + Dlib utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9cb094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmark_pt_list(mesh_results,width,height):\n",
    "    landmark_points_68 = [162,234,93,58,172,136,149,148,152,377,378,365,397,288,323,454,389,71,63,105,66,107,336,\n",
    "                  296,334,293,301,168,197,5,4,75,97,2,326,305,33,160,158,133,153,144,362,385,387,263,373,\n",
    "                  380,61,39,37,0,267,269,291,405,314,17,84,181,78,82,13,312,308,317,14,87]\n",
    "    \n",
    "    landmark_points_5_1 = [ 2, #bottom of nose tip\n",
    "                     362, #left eye towards centre\n",
    "                     263, #left eye away from centre\n",
    "                     33,  #right eye away from centre\n",
    "                     133 #right eye towards centre \n",
    "                    ]\n",
    "    landmark_points_5_2 = [ 2, #bottom of nose tip\n",
    "                     263, #left eye away from centre\n",
    "                     362, #left eye towards centre\n",
    "                     133, #right eye towards centre \n",
    "                     33  #right eye away from centre\n",
    "                    ]\n",
    "\n",
    "    if mesh_results.multi_face_landmarks:\n",
    "        for i,face_landmarks in enumerate(mesh_results.multi_face_landmarks): \n",
    "            if i==0:\n",
    "                raw_landmark_set = []\n",
    "                for index in landmark_points_5_1:\n",
    "                    x = int(face_landmarks.landmark[index].x * width)\n",
    "                    y = int(face_landmarks.landmark[index].y * height)\n",
    "                    landmark_point=dlib.point([x,y])\n",
    "                    raw_landmark_set.append(landmark_point)\n",
    "                    #display(landmark_point)\n",
    "                all_points=dlib.points(raw_landmark_set)\n",
    "#         return dlib.points([{\n",
    "#             \"nose_tip\": [raw_landmark_set[0]],\n",
    "#             \"left_eye\": raw_landmark_set[1:3],\n",
    "#             \"right_eye\": raw_landmark_set[3:],\n",
    "#         }])\n",
    "        return all_points\n",
    "\n",
    "def bounding_rect(detection_results,width,height):\n",
    "    if detection_results.detections:\n",
    "        for i,detection in enumerate(detection_results.detections):\n",
    "            if i==0:\n",
    "                # bbox data\n",
    "                bbox = detection.location_data.relative_bounding_box\n",
    "                xy_min = _normalized_to_pixel_coordinates(bbox.xmin, bbox.ymin, height,width)\n",
    "                xy_max = _normalized_to_pixel_coordinates(bbox.xmin + bbox.width, bbox.ymin + bbox.height,height,width)\n",
    "                if xy_min is None or xy_max is None:\n",
    "                    #print(\"face out of frame\")\n",
    "                    return\n",
    "                else:\n",
    "                    xmin,ymin =xy_min\n",
    "                    xmax,ymax = xy_max\n",
    "                    #bbox_points = { \"xmin\" : xmin,\"ymin\" : ymin,\"xmax\" : xmax,\"ymax\" : ymax}\n",
    "                    rectangle= dlib.rectangle(left=xmin, top=ymax, right=xmax, bottom=ymin)\n",
    "                    return rectangle\n",
    "\n",
    "def ret_encoding(filepath,num_jitters=1):\n",
    "    #image_input = cv2.imread(filepath)\n",
    "    #image_input = cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB)\n",
    "    image_input =face_recognition.load_image_file(filepath)\n",
    "    width,height=image_input.shape[:-1]\n",
    "    detection_results = face_detection.process(image_input)\n",
    "    mesh_results = face_mesh.process(image_input)\n",
    "    \n",
    "    all_points=  landmark_pt_list(mesh_results,width,height)  \n",
    "    print(\"all_points\", all_points)\n",
    "\n",
    "    b_box=bounding_rect(detection_results,width,height)\n",
    "    if (all_points is None) or (b_box is None):\n",
    "        return \n",
    "    raw_landmark_set=dlib.full_object_detection(b_box,all_points)\n",
    "    #display(all_points)\n",
    "    #display(b_box)\n",
    "    encodings=face_encoder.compute_face_descriptor(image_input, raw_landmark_set, num_jitters)\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df1a26",
   "metadata": {},
   "source": [
    "### Linear sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "577d2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_list(folder):\n",
    "    img_list=[]\n",
    "    for file in os.listdir(folder):\n",
    "        if not file.startswith('.') and os.path.isfile(os.path.join(folder, file)):\n",
    "            filepath = os.path.join(folder, file)\n",
    "            filepath=filepath.replace('\\\\' , '/')\n",
    "            img_list.append(file)\n",
    "    return img_list        \n",
    "    print(\"got image list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65210f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_d(enc1, enc2):\n",
    "    enc1=np.array(enc1)\n",
    "    enc2=np.array(enc2)\n",
    "    d=np.linalg.norm(enc1 - enc2, axis=0)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed1ede49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not df\n",
    "def encode_list(folder, img_list):\n",
    "    enc_dict={}\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(folder,img)\n",
    "        encoding=(ret_encoding(img_path))\n",
    "        enc_dict[img]=encoding \n",
    "    return enc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "859130ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not df\n",
    "def get_closest(folder, start_img, img_list, enc_dict):\n",
    "    img_list.remove(start_img)\n",
    "#     enc1=(ret_encoding(os.path.join(folder,start_img)))\n",
    "    enc1=enc_dict[start_img]\n",
    "    dist=[]\n",
    "    dist_dict={}\n",
    "    for img in img_list:\n",
    "#         file2=filebase+str(i)+\".jpg\".replace('\\\\' , '/')\n",
    "#         test_img = os.path.join(folder,img)\n",
    "#         enc2=(ret_encoding(test_img))\n",
    "        enc2 = enc_dict[img]\n",
    "        if (enc1 is not None) and (enc2 is not None):\n",
    "#             print(file2)\n",
    "            d = get_d(enc1, enc2)\n",
    "#             print(d)\n",
    "            dist.append(d)\n",
    "            dist_dict[d]=img\n",
    "    dist.sort()\n",
    "    print(len(dist))\n",
    "    return dist[0], dist_dict[dist[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "169ef9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sorted(folder, image, counter, dist):\n",
    "    sorted_name = \"linear_sort_\"+str(counter)+\"_\"+str(round(dist, 2))+\".jpg\"\n",
    "    sortfolder=\"sorted2\"\n",
    "    newfolder = os.path.join(folder,sortfolder)\n",
    "    old_name=os.path.join(folder,image)\n",
    "    new_name=os.path.join(newfolder,sorted_name)\n",
    "    if not os.path.exists(newfolder):\n",
    "        os.makedirs(newfolder)\n",
    "    shutil.copy(old_name, new_name)\n",
    "    print('saved, ',sorted_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec3081e",
   "metadata": {},
   "source": [
    "### dataframe creation and sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99858bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_list_df(folder, img_list):\n",
    "#     enc_dict={}\n",
    "    csv_name=\"face_encodings.csv\"\n",
    "    col1=\"file_name\"\n",
    "    col2=\"encoding\"\n",
    "    curr=0\n",
    "    total = len(img_list)\n",
    "\n",
    "    # encodings column list for splitting\n",
    "    col_list=[]\n",
    "    for i in range(128):\n",
    "        col_list.append(col2+str(i))\n",
    "\n",
    "    #initializing the dataframe\n",
    "    image_data=pd.DataFrame(columns=[col1, col2])\n",
    "\n",
    "    \n",
    "    for img in img_list:\n",
    "        if curr%10==0:print(curr,\"/\",total)\n",
    "        curr+=1\n",
    "        filepath = os.path.join(folder,img)        \n",
    "        filepath=filepath.replace('\\\\' , '/')  ## cv2 accepts files with \"/\" instead of \"\\\"\n",
    "        encodings=ret_encoding(filepath)\n",
    "        print(encodings)\n",
    "        if encodings is not None:              ## checking if a face is found\n",
    "            data=pd.DataFrame({col1:img,col2:[np.array(encodings)]})\n",
    "            image_data = pd.concat([image_data,data],ignore_index=True)  \n",
    "\n",
    "    #splitting the encodings column\n",
    "    output_data = pd.DataFrame(image_data[col2].to_list(), columns=col_list)\n",
    "    #adding the filename column and then puting it first\n",
    "    output_data[[col1]]=pd.DataFrame(image_data[col1].tolist(),index=image_data.index)\n",
    "    clms = output_data.columns.tolist()\n",
    "    clms = clms[-1:] + clms[:-1]\n",
    "    output_data=output_data[clms]\n",
    "    # saving without index\n",
    "    output_data.to_csv(csv_name, index=False)\n",
    "    df = pd.read_csv(csv_name)\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cea4dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_df(folder, start_img, df_enc):\n",
    "    if start_img == \"median\":\n",
    "        enc1 = df_enc.median().to_list()\n",
    "        print(\"in median\")\n",
    "        print(enc1)\n",
    "        \n",
    "    else:\n",
    "#         enc1 = get 2-129 from df via stimg key\n",
    "        enc1 = df_enc.loc[start_img].to_list()\n",
    "        df_enc=df_enc.drop(start_img)\n",
    "        print(\"in new img\",len(df_enc.index))\n",
    "        print(enc1)\n",
    "    \n",
    "#     img_list.remove(start_img)\n",
    "#     enc1=enc_dict[start_img]\n",
    "    \n",
    "    dist=[]\n",
    "    dist_dict={}\n",
    "    for index, row in df_enc.iterrows():\n",
    "#         print(row['c1'], row['c2'])\n",
    "#     for img in img_list:\n",
    "        enc2 = row\n",
    "        if (enc1 is not None) and (enc2 is not None):\n",
    "            d = get_d(enc1, enc2)\n",
    "            dist.append(d)\n",
    "            dist_dict[d]=index\n",
    "    dist.sort()\n",
    "#     print(len(dist))\n",
    "    return dist[0], dist_dict[dist[0]], df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73681356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if new and old make a face\n",
    "def is_face(image):\n",
    "    # For static images:\n",
    "    # I think this list is not used\n",
    "    IMAGE_FILES = []\n",
    "    with mp_face_detection.FaceDetection(model_selection=1, \n",
    "                                        min_detection_confidence=0.6\n",
    "                                        ) as face_detection:\n",
    "        # image = cv2.imread(file)\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "#         detection_results = face_detection.process(image)\n",
    "\n",
    "        results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Draw face detections of each face.\n",
    "        if not results.detections:\n",
    "            is_face = False\n",
    "        else:\n",
    "            is_face = True\n",
    "        # annotated_image = image.copy()\n",
    "        # for detection in results.detections:\n",
    "        #     is_face = True\n",
    "        #     print('Nose tip:')\n",
    "        #     print(mp_face_detection.get_key_point(\n",
    "        #       detection, mp_face_detection.FaceKeyPoint.NOSE_TIP))\n",
    "        #     mp_drawing.draw_detection(annotated_image, detection)\n",
    "        # cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
    "\n",
    "        return is_face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04ba4934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if new and old make a face\n",
    "def test_pair(last_file, new_file):\n",
    "    try:\n",
    "        img = cv2.imread(new_file)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width, height)\n",
    "        print('loaded img 1')\n",
    "        \n",
    "        last_img = cv2.imread(new_file)\n",
    "        last_height, last_width, last_layers = last_img.shape\n",
    "        last_size = (last_width, last_height)\n",
    "        print('loaded img 2')\n",
    "        \n",
    "        # test to see if this is actually an face, to get rid of blank ones/bad ones\n",
    "        if is_face(img):\n",
    "            print('new file is face')\n",
    "            # if not the first image\n",
    "#             if i>0:\n",
    "            # blend this image with the last image\n",
    "            blend = cv2.addWeighted(img, 0.5, last_img, 0.5, 0.0)\n",
    "            print('blended faces')\n",
    "            blended_face = is_face(blend)\n",
    "            print('is_face ',blended_face)\n",
    "            # if blended image has a detectable face, append the img\n",
    "            if blended_face:\n",
    "#                     img_array.append(img)\n",
    "                print('is a face! adding it')\n",
    "                return True\n",
    "            else:\n",
    "                print('skipping this one')\n",
    "                return False\n",
    "            # for the first one, just add the image\n",
    "            # this may need to be refactored in case the first one is bad?\n",
    "#             else:\n",
    "#                 print('this is maybe the first round?')\n",
    "#                 img_array.append(img)\n",
    "        else:\n",
    "            print('new_file is not face: ',new_file)\n",
    "            return False\n",
    "\n",
    "#         i+=1\n",
    "\n",
    "    except:\n",
    "        print('failed:',new_file)\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6543e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1\n",
      "all_points points[(377, 391), (416, 298), (478, 297), (280, 300), (340, 299)]\n",
      "-0.061921\n",
      "0.140973\n",
      "0.08619\n",
      "-0.0387943\n",
      "-0.0562281\n",
      "0.019817\n",
      "-0.0117129\n",
      "-0.0216239\n",
      "0.10788\n",
      "-0.0104584\n",
      "0.192774\n",
      "-0.0123732\n",
      "-0.222681\n",
      "0.00118411\n",
      "-0.0166932\n",
      "0.0531457\n",
      "-0.105079\n",
      "-0.0848444\n",
      "-0.167217\n",
      "-0.0897218\n",
      "0.0677555\n",
      "0.076692\n",
      "-0.0288127\n",
      "0.0110551\n",
      "-0.108417\n",
      "-0.273434\n",
      "-0.0866626\n",
      "-0.0532918\n",
      "0.0888838\n",
      "-0.105861\n",
      "0.00492426\n",
      "-0.0143789\n",
      "-0.148529\n",
      "0.00336208\n",
      "0.0203709\n",
      "0.0574094\n",
      "-0.0642199\n",
      "-0.0901583\n",
      "0.138616\n",
      "-0.0108976\n",
      "-0.158632\n",
      "-0.0218145\n",
      "0.0666546\n",
      "0.288828\n",
      "0.191716\n",
      "0.0509601\n",
      "-0.0109379\n",
      "-0.032333\n",
      "0.0727444\n",
      "-0.238263\n",
      "0.0623322\n",
      "0.198283\n",
      "0.0751028\n",
      "0.137286\n",
      "0.0929721\n",
      "-0.153943\n",
      "0.0168533\n",
      "0.136087\n",
      "-0.13104\n",
      "0.0597783\n",
      "0.0459218\n",
      "-0.0895244\n",
      "-0.0581754\n",
      "-0.132012\n",
      "0.163603\n",
      "0.10873\n",
      "-0.144596\n",
      "-0.175624\n",
      "0.0616783\n",
      "-0.199706\n",
      "-0.0604662\n",
      "0.097049\n",
      "-0.107556\n",
      "-0.142665\n",
      "-0.232489\n",
      "0.0732546\n",
      "0.424374\n",
      "0.191549\n",
      "-0.191587\n",
      "-0.00513528\n",
      "-0.0682206\n",
      "-0.00779673\n",
      "0.100121\n",
      "0.0618812\n",
      "-0.109472\n",
      "0.0180898\n",
      "-0.118126\n",
      "0.0333832\n",
      "0.190002\n",
      "-0.0353404\n",
      "-0.0183787\n",
      "0.18733\n",
      "-0.0124335\n",
      "0.00765711\n",
      "-0.011652\n",
      "0.0203076\n",
      "-0.107596\n",
      "0.00824197\n",
      "-0.0807324\n",
      "-0.0093837\n",
      "0.0584345\n",
      "-0.108977\n",
      "-0.00782825\n",
      "0.0948432\n",
      "-0.136028\n",
      "0.176959\n",
      "0.0387935\n",
      "0.0270101\n",
      "0.033334\n",
      "0.00430417\n",
      "-0.107055\n",
      "-0.0397141\n",
      "0.192697\n",
      "-0.249395\n",
      "0.174756\n",
      "0.17165\n",
      "0.0105452\n",
      "0.106534\n",
      "0.0978484\n",
      "0.145508\n",
      "-0.0180314\n",
      "-0.00581864\n",
      "-0.141529\n",
      "-0.0630563\n",
      "0.0131972\n",
      "-0.0204423\n",
      "0.0106721\n",
      "-0.015226\n",
      "               file_name  encoding0  encoding1  encoding2  encoding3  \\\n",
      "0  linear_sort_0_0.2.jpg  -0.061921   0.140973    0.08619  -0.038794   \n",
      "\n",
      "   encoding4  encoding5  encoding6  encoding7  encoding8  ...  encoding118  \\\n",
      "0  -0.056228   0.019817  -0.011713  -0.021624    0.10788  ...     0.097848   \n",
      "\n",
      "   encoding119  encoding120  encoding121  encoding122  encoding123  \\\n",
      "0     0.145508    -0.018031    -0.005819    -0.141529    -0.063056   \n",
      "\n",
      "   encoding124  encoding125  encoding126  encoding127  \n",
      "0     0.013197    -0.020442     0.010672    -0.015226  \n",
      "\n",
      "[1 rows x 129 columns]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "folder=\"/Users/michaelmandiberg/Documents/projects-active/facemap_production/just_start_image\"\n",
    "img_list = get_img_list(folder)\n",
    "\n",
    "# start_img = img_list[1]\n",
    "start_img = \"median\"\n",
    "\n",
    "# enc_dict = encode_list(folder, img_list)\n",
    "\n",
    "df_enc = encode_list_df(folder, img_list)\n",
    "print(df_enc)\n",
    "\n",
    "df_enc.set_index('file_name', inplace=True)\n",
    "\n",
    "\n",
    "#with lists/dicts\n",
    "# dist=0\n",
    "# for i in range(len(img_list)-1):\n",
    "#     save_sorted(folder, start_img, i, dist)\n",
    "#     dist, start_img = get_closest(folder, start_img,img_list, enc_dict)\n",
    "    \n",
    "#     print(dist)\n",
    "#     print (start_img)\n",
    "    \n",
    "#     if dist > .37: \n",
    "#         continue\n",
    "\n",
    "#with df\n",
    "dist=0\n",
    "print(len(df_enc.index))\n",
    "\n",
    "\n",
    "    \n",
    "for i in range(len(df_enc.index)-2):\n",
    "    dist, start_img, df_enc = get_closest_df(folder, start_img,df_enc)\n",
    "#     print(folder, start_img, i, dist)\n",
    "    save_sorted(folder, start_img, i, dist)\n",
    "    print(i)\n",
    "    print(len(df_enc.index))\n",
    "    print(dist)\n",
    "    print (start_img)\n",
    "    \n",
    "    if dist > .37: \n",
    "        break\n",
    "    \n",
    "    \n",
    "# I don't know why, but this isn't working\n",
    "# for i in range(len(df_enc.index)-2):\n",
    "#     dist, start_img, df_enc = get_closest_df(folder, start_img,df_enc)\n",
    "# #     print(folder, start_img, i, dist)\n",
    "#     save_sorted(folder, start_img, i, dist)\n",
    "\n",
    "#     if i>0:\n",
    "#         #test blend\n",
    "# #         last_file = os.path.join(folder,)\n",
    "#         blend_is_face = (test_pair(os.path.join(folder,last_img), os.path.join(folder,start_img)))\n",
    "#         print('blend_is_face ',blend_is_face)\n",
    "#         if blend_is_face:\n",
    "# #         print(test_pair(last_img,start_img))\n",
    "#             save_sorted(folder, start_img, i, dist)\n",
    "#             last_img = start_img\n",
    "# #         else:\n",
    "# #             start_img = last_img\n",
    "            \n",
    "#     print(i)\n",
    "#     print(len(df_enc.index))\n",
    "#     print(dist)\n",
    "#     print (start_img)\n",
    "    \n",
    "#     if dist > .37: \n",
    "#         break\n",
    "        \n",
    "       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280bd668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf856c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a4109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654606f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d801aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0801a5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Env37]",
   "language": "python",
   "name": "conda-env-Env37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
