{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb37d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import face_recognition_models\n",
    "import dlib\n",
    "import os\n",
    "from mediapipe.python.solutions.drawing_utils import _normalized_to_pixel_coordinates\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "import face_recognition\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a7d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognition_model = face_recognition_models.face_recognition_model_location()\n",
    "face_encoder = dlib.face_recognition_model_v1(face_recognition_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5795dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_points_68 = [162,234,93,58,172,136,149,148,152,377,378,365,397,288,323,454,389,71,63,105,66,107,336,\n",
    "                  296,334,293,301,168,197,5,4,75,97,2,326,305,33,160,158,133,153,144,362,385,387,263,373,\n",
    "                  380,61,39,37,0,267,269,291,405,314,17,84,181,78,82,13,312,308,317,14,87]\n",
    "    \n",
    "landmark_points_5_1 = [ 2, #bottom of nose tip\n",
    "                     362, #left eye towards centre\n",
    "                     263, #left eye away from centre\n",
    "                     33,  #right eye away from centre\n",
    "                     133 #right eye towards centre \n",
    "                    ]\n",
    "landmark_points_5_2 = [ 2, #bottom of nose tip\n",
    "                     263, #left eye away from centre\n",
    "                     362, #left eye towards centre\n",
    "                     133, #right eye towards centre \n",
    "                     33  #right eye away from centre\n",
    "                    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9f35cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.7)\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1,min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028bb5f",
   "metadata": {},
   "source": [
    "### MP + Dlib utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9cb094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmark_pt_list(mesh_results,width,height):\n",
    "    landmark_points_68 = [162,234,93,58,172,136,149,148,152,377,378,365,397,288,323,454,389,71,63,105,66,107,336,\n",
    "                  296,334,293,301,168,197,5,4,75,97,2,326,305,33,160,158,133,153,144,362,385,387,263,373,\n",
    "                  380,61,39,37,0,267,269,291,405,314,17,84,181,78,82,13,312,308,317,14,87]\n",
    "    \n",
    "    landmark_points_5_1 = [ 2, #bottom of nose tip\n",
    "                     362, #left eye towards centre\n",
    "                     263, #left eye away from centre\n",
    "                     33,  #right eye away from centre\n",
    "                     133 #right eye towards centre \n",
    "                    ]\n",
    "    landmark_points_5_2 = [ 2, #bottom of nose tip\n",
    "                     263, #left eye away from centre\n",
    "                     362, #left eye towards centre\n",
    "                     133, #right eye towards centre \n",
    "                     33  #right eye away from centre\n",
    "                    ]\n",
    "\n",
    "    if mesh_results.multi_face_landmarks:\n",
    "        for i,face_landmarks in enumerate(mesh_results.multi_face_landmarks): \n",
    "            if i==0:\n",
    "                raw_landmark_set = []\n",
    "                for index in landmark_points_5_1:\n",
    "                    x = int(face_landmarks.landmark[index].x * width)\n",
    "                    y = int(face_landmarks.landmark[index].y * height)\n",
    "                    landmark_point=dlib.point([x,y])\n",
    "                    raw_landmark_set.append(landmark_point)\n",
    "                    #display(landmark_point)\n",
    "                all_points=dlib.points(raw_landmark_set)\n",
    "#         return dlib.points([{\n",
    "#             \"nose_tip\": [raw_landmark_set[0]],\n",
    "#             \"left_eye\": raw_landmark_set[1:3],\n",
    "#             \"right_eye\": raw_landmark_set[3:],\n",
    "#         }])\n",
    "        return all_points\n",
    "\n",
    "def bounding_rect(detection_results,width,height):\n",
    "    if detection_results.detections:\n",
    "        for i,detection in enumerate(detection_results.detections):\n",
    "            if i==0:\n",
    "                # bbox data\n",
    "                bbox = detection.location_data.relative_bounding_box\n",
    "                xy_min = _normalized_to_pixel_coordinates(bbox.xmin, bbox.ymin, height,width)\n",
    "                xy_max = _normalized_to_pixel_coordinates(bbox.xmin + bbox.width, bbox.ymin + bbox.height,height,width)\n",
    "                if xy_min is None or xy_max is None:\n",
    "                    #print(\"face out of frame\")\n",
    "                    return\n",
    "                else:\n",
    "                    xmin,ymin =xy_min\n",
    "                    xmax,ymax = xy_max\n",
    "                    #bbox_points = { \"xmin\" : xmin,\"ymin\" : ymin,\"xmax\" : xmax,\"ymax\" : ymax}\n",
    "                    rectangle= dlib.rectangle(left=xmin, top=ymax, right=xmax, bottom=ymin)\n",
    "                    return rectangle\n",
    "\n",
    "def ret_encoding(filepath,num_jitters=1):\n",
    "    #image_input = cv2.imread(filepath)\n",
    "    #image_input = cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB)\n",
    "    image_input =face_recognition.load_image_file(filepath)\n",
    "    width,height=image_input.shape[:-1]\n",
    "    detection_results = face_detection.process(image_input)\n",
    "    mesh_results = face_mesh.process(image_input)\n",
    "    \n",
    "    all_points=  landmark_pt_list(mesh_results,width,height)  \n",
    "    b_box=bounding_rect(detection_results,width,height)\n",
    "    if (all_points is None) or (b_box is None):\n",
    "        return \n",
    "    raw_landmark_set=dlib.full_object_detection(b_box,all_points)\n",
    "    #display(all_points)\n",
    "    #display(b_box)\n",
    "    encodings=face_encoder.compute_face_descriptor(image_input, raw_landmark_set, num_jitters)\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df1a26",
   "metadata": {},
   "source": [
    "### Linear sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "577d2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_list(folder):\n",
    "    img_list=[]\n",
    "    for file in os.listdir(folder):\n",
    "        if not file.startswith('.') and os.path.isfile(os.path.join(folder, file)):\n",
    "            filepath = os.path.join(folder, file)\n",
    "            filepath=filepath.replace('\\\\' , '/')\n",
    "            img_list.append(file)\n",
    "    return img_list        \n",
    "    print(\"got image list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65210f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_d(enc1, enc2):\n",
    "    enc1=np.array(enc1)\n",
    "    enc2=np.array(enc2)\n",
    "    d=np.linalg.norm(enc1 - enc2, axis=0)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed1ede49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not df\n",
    "def encode_list(folder, img_list):\n",
    "    enc_dict={}\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(folder,img)\n",
    "        encoding=(ret_encoding(img_path))\n",
    "        enc_dict[img]=encoding \n",
    "    return enc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "859130ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not df\n",
    "def get_closest(folder, start_img, img_list, enc_dict):\n",
    "    img_list.remove(start_img)\n",
    "#     enc1=(ret_encoding(os.path.join(folder,start_img)))\n",
    "    enc1=enc_dict[start_img]\n",
    "    dist=[]\n",
    "    dist_dict={}\n",
    "    for img in img_list:\n",
    "#         file2=filebase+str(i)+\".jpg\".replace('\\\\' , '/')\n",
    "#         test_img = os.path.join(folder,img)\n",
    "#         enc2=(ret_encoding(test_img))\n",
    "        enc2 = enc_dict[img]\n",
    "        if (enc1 is not None) and (enc2 is not None):\n",
    "#             print(file2)\n",
    "            d = get_d(enc1, enc2)\n",
    "#             print(d)\n",
    "            dist.append(d)\n",
    "            dist_dict[d]=img\n",
    "    dist.sort()\n",
    "    print(len(dist))\n",
    "    return dist[0], dist_dict[dist[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "169ef9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sorted(folder, image, counter, dist):\n",
    "    sorted_name = \"linear_sort_\"+str(counter)+\"_\"+str(round(dist, 2))+\".jpg\"\n",
    "    sortfolder=\"sorted2\"\n",
    "    newfolder = os.path.join(folder,sortfolder)\n",
    "    old_name=os.path.join(folder,image)\n",
    "    new_name=os.path.join(newfolder,sorted_name)\n",
    "    if not os.path.exists(newfolder):\n",
    "        os.makedirs(newfolder)\n",
    "    shutil.copy(old_name, new_name)\n",
    "    print('saved, ',sorted_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec3081e",
   "metadata": {},
   "source": [
    "### dataframe creation and sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99858bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_list_df(folder, img_list):\n",
    "#     enc_dict={}\n",
    "    csv_name=\"face_encodings.csv\"\n",
    "    col1=\"file_name\"\n",
    "    col2=\"encoding\"\n",
    "    curr=0\n",
    "    total = len(img_list)\n",
    "\n",
    "    # encodings column list for splitting\n",
    "    col_list=[]\n",
    "    for i in range(128):\n",
    "        col_list.append(col2+str(i))\n",
    "\n",
    "    #initializing the dataframe\n",
    "    image_data=pd.DataFrame(columns=[col1, col2])\n",
    "\n",
    "    \n",
    "    for img in img_list:\n",
    "        if curr%10==0:print(curr,\"/\",total)\n",
    "        curr+=1\n",
    "        filepath = os.path.join(folder,img)        \n",
    "        filepath=filepath.replace('\\\\' , '/')  ## cv2 accepts files with \"/\" instead of \"\\\"\n",
    "        encodings=ret_encoding(filepath)\n",
    "        if encodings is not None:              ## checking if a face is found\n",
    "            data=pd.DataFrame({col1:img,col2:[np.array(encodings)]})\n",
    "            image_data = pd.concat([image_data,data],ignore_index=True)  \n",
    "\n",
    "    #splitting the encodings column\n",
    "    output_data = pd.DataFrame(image_data[col2].to_list(), columns=col_list)\n",
    "    #adding the filename column and then puting it first\n",
    "    output_data[[col1]]=pd.DataFrame(image_data[col1].tolist(),index=image_data.index)\n",
    "    clms = output_data.columns.tolist()\n",
    "    clms = clms[-1:] + clms[:-1]\n",
    "    output_data=output_data[clms]\n",
    "    # saving without index\n",
    "    output_data.to_csv(csv_name, index=False)\n",
    "    df = pd.read_csv(csv_name)\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cea4dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_df(folder, start_img, df_enc):\n",
    "    if start_img == \"median\":\n",
    "        enc1 = df_enc.median().to_list()\n",
    "#         print(\"in median\")\n",
    "    else:\n",
    "#         enc1 = get 2-129 from df via stimg key\n",
    "        enc1 = df_enc.loc[start_img].to_list()\n",
    "        df_enc=df_enc.drop(start_img)\n",
    "#         print(\"in new img\",len(df_enc.index))\n",
    "    \n",
    "#     img_list.remove(start_img)\n",
    "#     enc1=enc_dict[start_img]\n",
    "    \n",
    "    dist=[]\n",
    "    dist_dict={}\n",
    "    for index, row in df_enc.iterrows():\n",
    "#         print(row['c1'], row['c2'])\n",
    "#     for img in img_list:\n",
    "        enc2 = row\n",
    "        if (enc1 is not None) and (enc2 is not None):\n",
    "            d = get_d(enc1, enc2)\n",
    "            dist.append(d)\n",
    "            dist_dict[d]=index\n",
    "    dist.sort()\n",
    "#     print(len(dist))\n",
    "    return dist[0], dist_dict[dist[0]], df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73681356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if new and old make a face\n",
    "def is_face(image):\n",
    "    # For static images:\n",
    "    # I think this list is not used\n",
    "    IMAGE_FILES = []\n",
    "    with mp_face_detection.FaceDetection(model_selection=1, \n",
    "                                        min_detection_confidence=0.6\n",
    "                                        ) as face_detection:\n",
    "        # image = cv2.imread(file)\n",
    "        # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "#         detection_results = face_detection.process(image)\n",
    "\n",
    "        results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Draw face detections of each face.\n",
    "        if not results.detections:\n",
    "            is_face = False\n",
    "        else:\n",
    "            is_face = True\n",
    "        # annotated_image = image.copy()\n",
    "        # for detection in results.detections:\n",
    "        #     is_face = True\n",
    "        #     print('Nose tip:')\n",
    "        #     print(mp_face_detection.get_key_point(\n",
    "        #       detection, mp_face_detection.FaceKeyPoint.NOSE_TIP))\n",
    "        #     mp_drawing.draw_detection(annotated_image, detection)\n",
    "        # cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
    "\n",
    "        return is_face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04ba4934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if new and old make a face\n",
    "def test_pair(last_file, new_file):\n",
    "    try:\n",
    "        img = cv2.imread(new_file)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width, height)\n",
    "        print('loaded img 1')\n",
    "        \n",
    "        last_img = cv2.imread(new_file)\n",
    "        last_height, last_width, last_layers = last_img.shape\n",
    "        last_size = (last_width, last_height)\n",
    "        print('loaded img 2')\n",
    "        \n",
    "        # test to see if this is actually an face, to get rid of blank ones/bad ones\n",
    "        if is_face(img):\n",
    "            print('new file is face')\n",
    "            # if not the first image\n",
    "#             if i>0:\n",
    "            # blend this image with the last image\n",
    "            blend = cv2.addWeighted(img, 0.5, last_img, 0.5, 0.0)\n",
    "            print('blended faces')\n",
    "            blended_face = is_face(blend)\n",
    "            print('is_face ',blended_face)\n",
    "            # if blended image has a detectable face, append the img\n",
    "            if blended_face:\n",
    "#                     img_array.append(img)\n",
    "                print('is a face! adding it')\n",
    "                return True\n",
    "            else:\n",
    "                print('skipping this one')\n",
    "                return False\n",
    "            # for the first one, just add the image\n",
    "            # this may need to be refactored in case the first one is bad?\n",
    "#             else:\n",
    "#                 print('this is maybe the first round?')\n",
    "#                 img_array.append(img)\n",
    "        else:\n",
    "            print('new_file is not face: ',new_file)\n",
    "            return False\n",
    "\n",
    "#         i+=1\n",
    "\n",
    "    except:\n",
    "        print('failed:',new_file)\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6543e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 43\n",
      "10 / 43\n",
      "20 / 43\n",
      "30 / 43\n",
      "40 / 43\n",
      "43\n",
      "saved,  linear_sort_0_0.18.jpg\n",
      "0\n",
      "43\n",
      "0.18447030753633525\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct674_594.jpg\n",
      "saved,  linear_sort_1_0.27.jpg\n",
      "1\n",
      "42\n",
      "0.27107725459729737\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct674_605.jpg\n",
      "saved,  linear_sort_2_0.29.jpg\n",
      "2\n",
      "41\n",
      "0.2924295106427055\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct674_581.jpg\n",
      "saved,  linear_sort_3_0.31.jpg\n",
      "3\n",
      "40\n",
      "0.3130172183743331\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct261_6.jpg\n",
      "saved,  linear_sort_4_0.27.jpg\n",
      "4\n",
      "39\n",
      "0.2719206930593076\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct674_589.jpg\n",
      "saved,  linear_sort_5_0.35.jpg\n",
      "5\n",
      "38\n",
      "0.3477292769209953\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct674_585.jpg\n",
      "saved,  linear_sort_6_0.37.jpg\n",
      "6\n",
      "37\n",
      "0.36954107793852337\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct674_604.jpg\n",
      "saved,  linear_sort_7_0.35.jpg\n",
      "7\n",
      "36\n",
      "0.3461390179431415\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct261_4.jpg\n",
      "saved,  linear_sort_8_0.33.jpg\n",
      "8\n",
      "35\n",
      "0.3285754247629319\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct674_601.jpg\n",
      "saved,  linear_sort_9_0.32.jpg\n",
      "9\n",
      "34\n",
      "0.31820724772740233\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct261_1.jpg\n",
      "saved,  linear_sort_10_0.33.jpg\n",
      "10\n",
      "33\n",
      "0.32836533490550307\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct261_2.jpg\n",
      "saved,  linear_sort_11_0.34.jpg\n",
      "11\n",
      "32\n",
      "0.3358638457109755\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct261_5.jpg\n",
      "saved,  linear_sort_12_0.32.jpg\n",
      "12\n",
      "31\n",
      "0.32156759506479615\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct674_599.jpg\n",
      "saved,  linear_sort_13_0.26.jpg\n",
      "13\n",
      "30\n",
      "0.262991845532624\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct674_586.jpg\n",
      "saved,  linear_sort_14_0.29.jpg\n",
      "14\n",
      "29\n",
      "0.2929218493013766\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct674_583.jpg\n",
      "saved,  linear_sort_15_0.27.jpg\n",
      "15\n",
      "28\n",
      "0.2746603485329185\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct674_598.jpg\n",
      "saved,  linear_sort_16_0.25.jpg\n",
      "16\n",
      "27\n",
      "0.2521109239112531\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct674_584.jpg\n",
      "saved,  linear_sort_17_0.3.jpg\n",
      "17\n",
      "26\n",
      "0.30476439493162416\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct674_600.jpg\n",
      "saved,  linear_sort_18_0.37.jpg\n",
      "18\n",
      "25\n",
      "0.37157893257126695\n",
      "faceimg_crop1_X-20toX1_Y-4toY4_Z-3toZ3_maxResize0.5_ct674_579.jpg\n"
     ]
    }
   ],
   "source": [
    "folder=\"/Users/michaelmandiberg/Documents/projects-active/facemap_production/images1674272442.9258912/test\"\n",
    "img_list = get_img_list(folder)\n",
    "\n",
    "# start_img = img_list[1]\n",
    "start_img = \"median\"\n",
    "\n",
    "# enc_dict = encode_list(folder, img_list)\n",
    "df_enc = encode_list_df(folder, img_list)\n",
    "\n",
    "df_enc.set_index('file_name', inplace=True)\n",
    "\n",
    "\n",
    "#with lists/dicts\n",
    "# dist=0\n",
    "# for i in range(len(img_list)-1):\n",
    "#     save_sorted(folder, start_img, i, dist)\n",
    "#     dist, start_img = get_closest(folder, start_img,img_list, enc_dict)\n",
    "    \n",
    "#     print(dist)\n",
    "#     print (start_img)\n",
    "    \n",
    "#     if dist > .37: \n",
    "#         continue\n",
    "\n",
    "#with df\n",
    "dist=0\n",
    "print(len(df_enc.index))\n",
    "\n",
    "\n",
    "    \n",
    "for i in range(len(df_enc.index)-2):\n",
    "    dist, start_img, df_enc = get_closest_df(folder, start_img,df_enc)\n",
    "#     print(folder, start_img, i, dist)\n",
    "    save_sorted(folder, start_img, i, dist)\n",
    "    print(i)\n",
    "    print(len(df_enc.index))\n",
    "    print(dist)\n",
    "    print (start_img)\n",
    "    \n",
    "    if dist > .37: \n",
    "        break\n",
    "    \n",
    "    \n",
    "# I don't know why, but this isn't working\n",
    "# for i in range(len(df_enc.index)-2):\n",
    "#     dist, start_img, df_enc = get_closest_df(folder, start_img,df_enc)\n",
    "# #     print(folder, start_img, i, dist)\n",
    "#     save_sorted(folder, start_img, i, dist)\n",
    "\n",
    "#     if i>0:\n",
    "#         #test blend\n",
    "# #         last_file = os.path.join(folder,)\n",
    "#         blend_is_face = (test_pair(os.path.join(folder,last_img), os.path.join(folder,start_img)))\n",
    "#         print('blend_is_face ',blend_is_face)\n",
    "#         if blend_is_face:\n",
    "# #         print(test_pair(last_img,start_img))\n",
    "#             save_sorted(folder, start_img, i, dist)\n",
    "#             last_img = start_img\n",
    "# #         else:\n",
    "# #             start_img = last_img\n",
    "            \n",
    "#     print(i)\n",
    "#     print(len(df_enc.index))\n",
    "#     print(dist)\n",
    "#     print (start_img)\n",
    "    \n",
    "#     if dist > .37: \n",
    "#         break\n",
    "        \n",
    "       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280bd668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf856c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a4109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654606f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d801aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Env37]",
   "language": "python",
   "name": "conda-env-Env37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
